{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZTnw0DhQ76x"
      },
      "source": [
        "# DATA PREPROCESSING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnJ3yJiC9FoW",
        "outputId": "3deaca92-3093-4319-87ba-4d486288965e"
      },
      "outputs": [],
      "source": [
        "# DATA PREPROCESSING\n",
        "# MFCCs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tables  \n",
        "import librosa\n",
        "import librosa.display\n",
        "# time taken to read data\n",
        "chunk = pd.read_excel('ESC-50-master/meta/miniesc50.xlsx',usecols=['filename','category'])\n",
        "classes = chunk['category']\n",
        "audiofiles = chunk['filename']\n",
        "\n",
        "mfccFeatures = []\n",
        "i = 0\n",
        "for wavFile in audiofiles:\n",
        "    data, samplingRate = librosa.load(('ESC-50-master/audio/' + wavFile), sr=24050)\n",
        "\n",
        "    #Grab the mfcc features through the mfcc algorithm\n",
        "    mfcc = librosa.feature.mfcc(data,sr=samplingRate,n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfcc.T,axis=0)\n",
        "\n",
        "\n",
        "    mfccFeatures.append([mfccs_scaled_features,classes[i]])\n",
        "    i += 1\n",
        "    if (i == 200):\n",
        "        break\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "mfccFeatures = pd.DataFrame(mfccFeatures, columns=['feature','class_category'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yqGHFQdRMOt"
      },
      "source": [
        "# MODEL CREATION AND TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9OtTemqy9-u",
        "outputId": "7c9da0e7-53c0-4159-8b43-9c794abf7f19"
      },
      "outputs": [],
      "source": [
        "# MODEL CREATION AND TESTING\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tables  \n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn import metrics \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from ann_visualizer.visualize import ann_viz;\n",
        "\n",
        "# from tensorflow import keras \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from numpy import load\n",
        "\n",
        "X = load('X.npy')\n",
        "\n",
        "Y = load('Y.npy')\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "#Encode target labels with value between 0 and n-1 classes\n",
        "Label_encoder = LabelEncoder()\n",
        "yy=to_categorical((Label_encoder.fit_transform(Y)))\n",
        "\n",
        "\n",
        "#performing train test split on our data set.\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,yy,test_size=0.40,shuffle = True, random_state=2)\n",
        "\n",
        "num_labels=yy.shape[1]\n",
        "\n",
        "model=Sequential()\n",
        "#first layer\n",
        "model.add(Dense(256,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# To compile the model we need to define loss function which is categorical cross-entropy,\n",
        "# accuracy metrics which is accuracy score, and an optimizer which is Adam.\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "model.summary()\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "accuracy = 400*score[1]\n",
        "\n",
        "# TESTING BEFORE TRAINING\n",
        "print(f'the accuracy {accuracy} before training')\n",
        "\n",
        "# TRAINING\n",
        "num_epochs = 200\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='./audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, Y_test), callbacks=[checkpointer] ,verbose=1)\n",
        "\n",
        "# EVALUATING AFTER TRAINING\n",
        "score = model.evaluate(X_train, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))\n",
        "\n",
        "\n",
        "\n",
        "# PREDICTION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ONE PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfkAnDO2OW7V",
        "outputId": "05f73cd9-beea-45cb-8f7e-266ec340a59f"
      },
      "outputs": [],
      "source": [
        "filename=\"output.wav\"\n",
        "\n",
        "#preprocess the audio file\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "#Reshape MFCC feature to 2-D array\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "x_predict=model.predict(mfccs_scaled_features) \n",
        "predicted_label=np.argmax(x_predict,axis=1)\n",
        "\n",
        "prediction_class = Label_encoder.inverse_transform(predicted_label) \n",
        "print(prediction_class)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 25 SAMPLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json\n",
        "# import base64\n",
        "# import asyncio\n",
        "# import pyaudio\n",
        "# import websockets\n",
        "\n",
        "\n",
        "# FRAMES_PER_BUFFER = 3200\n",
        "# FORMAT = pyaudio.paInt16\n",
        "# CHANNELS = 1\n",
        "# RATE = 16000\n",
        "# p = pyaudio.PyAudio()\n",
        "\n",
        "# # starts recording\n",
        "# stream = p.open(\n",
        "#     format=FORMAT,\n",
        "#     channels=CHANNELS,\n",
        "#     rate=RATE,\n",
        "#     input=True,\n",
        "#     frames_per_buffer=FRAMES_PER_BUFFER\n",
        "# )\n",
        "\n",
        "# URL = \"wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000\"\n",
        "\n",
        "\n",
        "# async def send_receive():\n",
        "#     print(f'Connecting websocket to url ${URL}')\n",
        "#     async with websockets.connect(\n",
        "#             URL,\n",
        "#             extra_headers=((\"Authorization\", \"8209d9a235da421b9cee1305c901b2de\"),),\n",
        "#             ping_interval=5,\n",
        "#             ping_timeout=20\n",
        "#     ) as _ws:\n",
        "#         await asyncio.sleep(0.1)\n",
        "#         print(\"Receiving Session Begins ...\")\n",
        "#         session_begins = await _ws.recv()\n",
        "#         print(session_begins)\n",
        "#         print(\"Sending messages ...\")\n",
        "\n",
        "#         async def send():\n",
        "#             while True:\n",
        "#                 try:\n",
        "#                     data = stream.read(FRAMES_PER_BUFFER)\n",
        "#                     data = base64.b64encode(data).decode(\"utf-8\")\n",
        "#                     json_data = json.dumps({\"audio_data\": str(data)})\n",
        "#                     await _ws.send(json_data)\n",
        "#                 except websockets.exceptions.ConnectionClosedError as e:\n",
        "#                     print(e)\n",
        "#                     assert e.code == 4008\n",
        "#                     break\n",
        "#                 except Exception as e:\n",
        "#                     assert False, \"Not a websocket 4008 error\"\n",
        "#                 await asyncio.sleep(0.01)\n",
        "\n",
        "#             return True\n",
        "\n",
        "#         async def receive():\n",
        "#             while True:\n",
        "#                 try:\n",
        "#                     result_str = await _ws.recv()\n",
        "#                     print(json.loads(result_str)['text'])\n",
        "#                 except websockets.exceptions.ConnectionClosedError as e:\n",
        "#                     print(e)\n",
        "#                     assert e.code == 4008\n",
        "#                     break\n",
        "#                 except Exception as e:\n",
        "#                     assert False, \"Not a websocket 4008 error\"\n",
        "\n",
        "#         send_result, receive_result = await asyncio.gather(send(), receive())\n",
        "\n",
        "# # asyncio.run(send_receive())\n",
        "# test,receive_result = await send_receive()\n",
        "\n",
        "\n",
        "# filename=\"testSounds/sirening.wav\"\n",
        "\n",
        "# #preprocess the audio file\n",
        "# audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "# mfccs_features = librosa.feature.mfcc(y=test, sr=sample_rate, n_mfcc=40)\n",
        "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "# #Reshape MFCC feature to 2-D array\n",
        "# mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "# x_predict=model.predict(mfccs_scaled_features) \n",
        "# predicted_label=np.argmax(x_predict,axis=1)\n",
        "\n",
        "# prediction_class = Label_encoder.inverse_transform(predicted_label) \n",
        "# print(prediction_class)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LIVE LISTENING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5 SECOND LISTENING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[Errno -9998] Invalid number of channels",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m WAVE_OUTPUT_FILENAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m p \u001b[39m=\u001b[39m pyaudio\u001b[39m.\u001b[39mPyAudio()\n\u001b[1;32m---> 13\u001b[0m stream \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mopen(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mFORMAT,\n\u001b[0;32m     14\u001b[0m                 channels\u001b[39m=\u001b[39;49mCHANNELS,\n\u001b[0;32m     15\u001b[0m                 rate\u001b[39m=\u001b[39;49mRATE,\n\u001b[0;32m     16\u001b[0m                 \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     17\u001b[0m                 frames_per_buffer\u001b[39m=\u001b[39;49mCHUNK)\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m* recording\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m frames \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    632\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \n\u001b[0;32m    634\u001b[0m \u001b[39m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     stream \u001b[39m=\u001b[39m PyAudio\u001b[39m.\u001b[39mStream(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streams\u001b[39m.\u001b[39madd(stream)\n\u001b[0;32m    641\u001b[0m     \u001b[39mreturn\u001b[39;00m stream\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[1;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[0;32m    438\u001b[0m     arguments[\u001b[39m'\u001b[39m\u001b[39mstream_callback\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m stream_callback\n\u001b[0;32m    440\u001b[0m \u001b[39m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mopen(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39marguments)\n\u001b[0;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39minputLatency\n\u001b[0;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39moutputLatency\n",
            "\u001b[1;31mOSError\u001b[0m: [Errno -9998] Invalid number of channels"
          ]
        }
      ],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 2\n",
        "RATE = 24050\n",
        "RECORD_SECONDS = 5\n",
        "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "print(\"* recording\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "    data = stream.read(CHUNK)\n",
        "    frames.append(data)\n",
        "\n",
        "#################\n",
        "\n",
        "#################\n",
        "print(\"* done recording\")\n",
        "\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "\n",
        "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf.setframerate(RATE)\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()\n",
        "\n",
        "\n",
        "filename=\"output.wav\"\n",
        "\n",
        "#preprocess the audio file\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "#Reshape MFCC feature to 2-D array\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "x_predict=model.predict(mfccs_scaled_features) \n",
        "predicted_label=np.argmax(x_predict,axis=1)\n",
        "\n",
        "prediction_class = Label_encoder.inverse_transform(predicted_label) \n",
        "print(prediction_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LIVE LISTENING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyaudio\n",
        "import numpy as np\n",
        "import librosa\n",
        "import warnings\n",
        "import threading\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#This will ignore all DeprecationWarning warnings in your code.\n",
        "CHUNKSIZE = 1024\n",
        "SR = 24050\n",
        "\n",
        "stream_active = True\n",
        "stop_event = threading.Event()\n",
        "\n",
        "def audio_callback(in_data, frame_count, time_info, status):\n",
        "# if stream_active:\n",
        "    audio_data = np.frombuffer(in_data, dtype=np.int16) / 32767.0 # scale audio data to [-1, 1]\n",
        "    audio_data = librosa.resample(audio_data, SR, 16000) # resample audio data to 16 kHz\n",
        "    mfccs_features = librosa.feature.mfcc(audio_data, sr=SR, n_mfcc=40) # compute MFCCs\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "    #Reshape MFCC feature to 2-D array\n",
        "    mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "    x_predict=model.predict(mfccs_scaled_features) \n",
        "    predicted_label=np.argmax(x_predict,axis=1)\n",
        "\n",
        "    prediction_class = Label_encoder.inverse_transform(predicted_label) \n",
        "    print(prediction_class)\n",
        "\n",
        "    # preprocess audio data and do sound classification here\n",
        "    return (audio_data * 32767.0).astype(np.int16), pyaudio.paContinue\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "stream = p.open(format=pyaudio.paInt16,\n",
        "                channels=1,\n",
        "                rate=SR,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNKSIZE,\n",
        "                stream_callback=audio_callback)\n",
        "\n",
        "stream.start_stream()\n",
        "\n",
        "# while stream.is_active:\n",
        "#     pass\n",
        "try:\n",
        "    while not stop_event.is_set():\n",
        "        # do other things here while audio is being recorded and processed\n",
        "        pass\n",
        "except KeyboardInterrupt:\n",
        "    stop_event.set()\n",
        "\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
